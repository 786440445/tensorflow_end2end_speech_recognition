param:
  model: blstm_attention
  corpus: timit
  label_type: phone61
  feature: fbank
  input_size: 120
  encoder_num_unit: 256
  encoder_num_layer: 4
  attention_dim: 128
  attention_type: content
  decoder_num_unit: 256
  decoder_num_layer: 1
  embedding_dim: 32
  max_decode_length: 50
  attention_smoothing: True
  attention_weights_tempareture: 1.0
  logits_tempareture: 1.0
  batch_size: 64
  optimizer: adam
  learning_rate: 1e-3
  decay_start_epoch: 20
  decay_rate: 0.5
  decay_patient_epoch: 3
  num_epoch: 50
  weight_init: 0.1
  clip_grad: 5.0
  clip_activation_encoder: 50
  clip_activation_decoder: 50
  dropout_input: 0.8
  dropout_hidden: 0.5
  dropout_output: 1.0
  weight_decay: 0
  beam_width: 20
  eval_start_epoch: 20
  print_step: 10
